---
title: "How Work in R Gets Shared"
author: "Steven M. Mortimer"
date: "12/11/2018"
output: 
  github_document:
    toc: true
    toc_depth: 2
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = FALSE)
```

# Sharing with R Users

<p align="center">
  <img src="./img/xkcd-documents.png" height="400px" />
</p>  

## R Project Folder Structures

Many programming languages and frameworks use folder structures for configuration and 
extensibility. To not use a standard would mean reinventing the wheel each time and 
risk confusing/slowing down collaborators. This problem has been tackled by many 
individuals in the R community. Based on their suggestions I have adapted the following 
structure to be quick and easy to use: 

<p align="center">
  <img src="./img/folder-structure.png" height="300px" />
</p>  

The key features of this structure is that you physically separate the inputs, 
intermediate data, and outputs into three different folders: 

 1. `data`: Folder for put raw, unprocessed data
 2. `cache`: Folder for intermediate data, if needed
 3. `output`: Folder for cleaned data, plots, etc.
 
There are two remaining folders in the structure: 

<ol start="4">
  <li><code>docs</code>: Folder for supporting articles, explanations, and other documentation</li>
  <li><code>R</code>: Folder for R scripts that hold global settings or functions if needed</li>
</ol>

Oftentimes you have a few R scripts that are long and complicated. I recommend breaking 
up sequential steps into smaller files that numbered so that the order to run 
them is obvious and then call each of them using the `source()` function. This way 
you can create a file called `main.R` that you can configure to run all of your 
analysis from one file. 

An example of a `main.R` file might look like this: 

```{r main-example, eval=FALSE}
# set runtime options and load packages ------------------------------

options(stringsAsFactors = FALSE, scipen = 99)

suppressMessages(library(here)) # to manage file paths
suppressMessages(library(tidyverse)) # to process data

# load R scripts that contains variables and functions for the analysis
source(here::here("R", "globals.R"))
source(here::here("R", "helpers.R"))

# create a folder for storing the output of the analysis from today
# this way your output doesn't accidentally get overwritten from another time
todays_date_formatted <- format(Sys.Date(), '%Y%m%d')
dir.create(here::here('output', todays_date_formatted), showWarnings = FALSE)

# sourcing scripts to run analysis -----------------------------------

source(here::here('01-wrangle.R'))
source(here::here('02-model.R'))
```

### Caching

Sometimes your project will involve a very large dataset or a sequence of complex and 
long-running processing steps. "Caching" is a term for saving off your analysis 
mid-way through the process so that you can restart it exactly from that particular 
spot. R Markdown documents have this built into them, but you can also do this from 
any R script by using the package **simpleCache**. **simpleCache** was created at 
the University of Virginia in part by the UVA R Users Group leader, VP (Pete) Nagraj.
Below is an example that uses a simulation to confirm the theoretical standard error. 
The value is stored in the variable `std_err`. The caching process will check the 
`cache` folder and if the object exists, then that block of code is not run and 
the cached output is loaded from the cache folder. If the cached object is not found, 
then the code runs, creates the object, and saves it to the cache folder.
 
```{r cache-example, eval=FALSE}
suppressMessages(library(here))  # for file management
suppressMessages(library(simpleCache)) # for caching long running parts of the script 

# set the cache directory
setCacheDir(here::here('cache'))
# delete the files if you want to refresh the cache or run `deleteCaches()` 

# the mean of 1000 standard normal observations has a standard deviation 
# that should approach 1/sqrt(1000) = 0.0316
simpleCache("std_err", {
  n_sample_avgs <- numeric(100)
  for(i in 1:100){
    n_sample_avgs[i] <- mean(rnorm(1000, 0, 1))
  }
  sd(n_sample_avgs)
})
```

### Resources

Here is a list of resources to help you review and inform your approach: 

 - [**RProjectTemplate**](http://projecttemplate.net/architecture.html) by John Myles White
 - [**pRojects**](https://itsalocke.com/projects/) by Steph Locke
 - [**new-project-template**](https://github.com/pavopax/new-project-template) by Paul Paczuski
 - [**Cookiecutter Data Science**](https://drivendata.github.io/cookiecutter-data-science/#directory-structure) (it is for Python, but applies to R)
 
## GitHub + Git flow

Once you have worked hard on creating a project in R you typically want to do 2 things: 

 1. Backup the work you've done
 2. Share it with others
 
GitHub is the de facto place to accomplish both of these tasks at once. GitHub is 
an online (cloud) service owned by Microsoft that allows developers to not only 
host their code, but collaborate with others on it there. They have designed a 
nice website to see what is happening with your code. The process of putting your 
code onto GitHub involves using **git**, which is a version control tool. It tracks 
changes to your files, which GitHub displays on their website along with the files. 

### Git Branches

 - Pull from Git Scenarios Talk (walk through examples?)

## R Package Structure

There is a common adage that if you have more than two functions in your project then you 
should consider bundling them into an R package. Hadley Wickham brings up the point that 
packages conform to a standard, so you do not have to think about structuring your work 
and they save you time because of all the tools made to support package builders. 

CRAN (Comprehensive R Archive Network) is a central location where fully-vetted R 
packages are shared with the world, but you can just as easily create and share packages 
in a shared folder, on GitHub, or elsewhere. For example, many R packages are hosted 
on GitHub, so if you want to install them, you do not need to get it from CRAN. You 
can go straight to the source on GitHub and download it like so: 

```{r package-github-download, eval=FALSE}
library(devtools)
install_github('tidyverse/dplyr') # {{username}}/{{package name}}
```

### Package Architecture

There can be a lot of files in an R package, but perhaps the most exciting structure and 
tool that Hadley was talking about is the ability to generate documentation and examples 
for your R functions. First, you create a folder called `R` that keeps `.R` scripts. 
If you add documentation above each function, then a package called **roxygen** will 
generate the `?help` pages (in the package's `man` folder). This is how all packages 
have a PDF index of functions and the "Help" pane in RStudio. Here is a side-by-side 
example of a function's documentation is created.

***
INSERT IMAGE HERE

***

Create test-package

 - DESCRIPTION?
 
### Package Testing/Integrity 

 - tests
 - travis
 - codecov
 
### Resources

Here are two of the best resources to help you create a package:

 - [**R Packages**](http://r-pkgs.had.co.nz) by Hadley Wickham
 - [*Writing an R Package from scratch*](https://hilaryparker.com/2014/04/29/writing-an-r-package-from-scratch/) by Hilary Parker
 - [**sayhello**]() - a basic example package with only one function
 
# Sharing with non-R Users

## Google Sheets

 - Example of how to do it (create a public spreadsheet and let people push to it)
 - talk about auth a little
 - Show Version History benefit

## R Markdown

 - describe markdown
 - describe chunk
 - show Caching
 - show how this document works (Rmd -> github md)

## Shiny + HTML/CSS/JavaScript

 - talk about ui.R, server.R
 
### Reactivity

### Shiny App Example
 
 - pull example from Packt book

### Shiny App Tips
 
 - give pro tips on building a shiny app
