---
title: "Hacking It In the Tidyverse"
author: "Steven M. Mortimer"
date: "9/14/2018"
output: 
  github_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = FALSE)
```

# Functions

## Naming functions

> There are only two hard things in Computer Science: cache invalidation and naming things.
>   -- Phil Karlton

Remember 2 things: 

1. snake_case - all lowercase, underscore separated
2. variables are nouns and functions are verbs

Examples:  
 
 - **dplyr** - `mutate()`, `select()`, `sample()`, `slice()`
 - **httr** - `GET()`, `POST()`, `PUT()`, `PATCH()`  
 vs.  
 - **dplyr** - `diamonds`, `mtcars`, `nycflights13`

## Basic function structure

Functions have 3 things: 

 1. environment (a name puts it in the current, global environment)
 2. arguments (usually)
 3. body (aka logic)
 
Here is a simple function:
 
```{r} 
rename <- function(x){
  paste0(x, " - v2")
}
```

Here is what it does:

```{r}
rename("cat")
```

## Where functions exist

Functions exist in the current, Global environment. They overwrite package functions. 
Try loading the **dplyr** package after we've created our function called `rename()`.

```{r}
library(dplyr)
```

Just to clear up our environment, let's remove the function and restart the R session, 
which unloads the **dplyr** package.

```{r} 
# Get rid of our test function
rm(rename)
# also run SHIFT+CMD+F10 to restart your R session
```

## Specify function values with return()

A function returns, by default the last evaluated value. 

Look at the differences in the next three functions and what they return.

**Function #1**

```{r}
# this function returns nothing
square_root <- function(x){
  x <- sqrt(x)
}
square_root(4) # wait, nothing happened?
```

```{r}
# let's assign the value from this function
y <- square_root(4)
y # it does actually return something!
```

**Function #2**

```{r}
# this function prints to the console
square_root <- function(x){
  sqrt(x)
}
square_root(4)
```

**Function #3**

```{r}
# this function works
square_root <- function(x){
  x <- sqrt(x)
  return(x)
}
square_root(4)
```

**Lession**: Try be explicit in what your functions return.

There is a raging debate on StackOverflow [here](https://stackoverflow.com/questions/11738823/explicitly-calling-return-in-a-function-or-not), 
but see the following example. It's not clear what the function returns.

```{r}
square_root <- function(x){
  if(x < 0){
    1
  } else {
    sqrt(x)
  }
}
```

A better version of this function makes it very clear that a result (`res`) gets 
returned. That result is either 0 or the square root based on the value of the input.

```{r}
square_root <- function(x){
  if(x < 0){
    res <- 0
  } else {
    res <- sqrt(x)
  }
  return(res)
}
```

## Hiding the output of your function with invisible()

If you look at the iris dataset you can see that the values for the `Sepal.Length` 
variable do not exceed 7.9.

```{r}
iris_dat <- iris
# The max Sepal Length in the iris dataset is 7.9
summary(iris_dat$Sepal.Length)
```

Let's say that we need a function that fixes values in the dataset if they are above 
a certain value. We'll call that function `cap_sepal_lengths()`. It's defined like this: 

```{r}
cap_sepal_lengths <- function(iris_dat, max_sep_len=8){
  fixes_made <- FALSE
  if(any(iris_dat$Sepal.Length > max_sep_len)){
    iris_dat$Sepal.Length[iris_dat$Sepal.Length > max_sep_len] <<- max_sep_len
    fixes_made <- TRUE
  }
  invisible(fixes_made)
}
```

When you run the function it doesn't output anything.

```{r}
cap_sepal_lengths(iris_dat)
```

When you run the function and assign the value to a variable (`fix_check1`), then 
you can see that the value is `FALSE`. This means that when we ran the function, 
none of the values in the dataset needed to be capped.

```{r}
fix_check1 <- cap_sepal_lengths(iris_dat)
fix_check1
```

Now consider a second example, where want to cap all values at 6. 

```{r}
fix_check2 <- cap_sepal_lengths(iris_dat, max_sep_len=6)
fix_check2
```

In this example you can see that the returned value is `TRUE` meaning that some values 
did end up needing fixing. The call to `summary` verifies that all values no longer 
exceed 6.

```{r}
summary(iris_dat$Sepal.Length)
```

**Lesson**: Sometimes functions should have side-effect behaviors and `invisible()` can 
report back the status for us if we are interested in capturing and using.

## Specifying default function argument values

It's usually a good idea to specify default values wherever possible. It makes it 
quicker to use a function that you've created. These values should be provided in 
your function definition.

```{r}
square_root <- function(x = 4){
  return(sqrt(x))
}
square_root()
square_root(25)
```

In this case, you can specify the `x2` default argument by using the `x` argument. 
This is called 

```{r}
square_root_plus <- function(x, x2=x^2){
  return(sqrt(x+x2))
}
square_root_plus(4) # sqrt(4 + 16)
square_root_plus(x=4, x2=12) # sqrt(4 + 12)
```

## Argument matching in functions

When calling a function you can specify arguments by position, by complete name, 
or by partial name. Arguments are matched first by exact name (perfect matching), 
then by prefix matching, and finally by position.

```{r}
paste_letters <- function(one="1", two="2", three="3"){
  return(paste(one, two, three, sep="-"))
}
paste_letters("a", "b", "c")
paste_letters("a", , "c") # weird positional matching
paste_letters(tw="a", th="b", "c") # prefix matching
try(paste_letters(t="a", t="b", "c")) # prefix matching
```

## Use NULL as the default value for missing arguments

A lot of times you'll have arguments that don't get used. The best way to deal with 
these is to use `NULL`. 

```{r}
paste_letters <- function(one="1", two="2", three=NULL){
  if(is.null(three)){
    res <- paste(one, two, sep="-")  
  } else {
    res <- paste(one, two, three, sep="-")
  }
  return(res)
}
paste_letters("a", "b")
```

## What do those dots (...) mean?

The dots are passthrough mechanism to provide any other named arguments that the 
function doesn't have explicity named. The body of the function will specify what 
to do with them. Usually they will be used as the inputs to another function. 
Check out the `lm()` function body to see where the dots go.

```{r}
lm
```

They are provided to the `lm.fit()` or `lm.wfit()` functions. If you look at those 
functions using `?lm.fit`, you'll see that there are some arguments that we could 
be specifying in our original `lm()` call to control how things work. For exmaple, 
the `tol` argument can be specified.

```{r}
lm(mpg ~ wt, data=mtcars)
lm(mpg ~ wt, data=mtcars, tol=1e-3)
```

If you create a function like this, try to always direct users to where the dots 
are going, so they can determine what arguments will actually work when they pass them 
in.

```{r}
# instead of having to specify a function like this:
messaged_mean <- function(x, trim, na.rm=FALSE){
  y <- mean(x=x, trim=trim, na.rm=na.rm)
  message(sprintf("The mean is: %1.3f", y))
  invisible(y)
}
# you can specify it like this in order to allow the passthrough effect
messaged_mean <- function(x, ...){
  y <- mean(x=x, ...)
  message(sprintf("The mean is: %1.3f", y))
  invisible(y)
}
messaged_mean(x=c(1:10,50), trim=0)
messaged_mean(x=c(1:10,50), trim=.1)
```

## Functions with a dot in the name

You may notice that sometimes functions have a dot in the name. Most of the time 
the package developer is trying to make the name more readable, but this is not 
always the case. Look at the print function: 

```{r}
print
```

There's not much to the function and you can see that it includes those dots. This 
is basically defining a function called "print" that takes an object and some other 
unnamed arguments and does something. We're not sure what though. Now let's look 
at the function `print.data.frame`:

```{r}
print.data.frame
```

You can see that whenever you print a `data.frame` you can control the number 
of digits, quoting, etc. The body of the function contains the familiar logic of 
what gets printed to the screen when you look at a data.frame. The `print()` 
function is called a generic. When you run it R will look for a more specific version 
of print that knows how to handle the specific object type that you passed to it. 
In this case, it will print a data.frame according to the function `print.data.frame`. 
A couple simple examples of this at work are: 

```{r}
print(head(iris))
print(Sys.time())
```

## Writing recursive functions

It's possible to have functions call themselves! This is really hard to get your 
head around, but sometimes very useful. Let's say you need to perform something 
over and over until a certain point. In this example, we'll take half a number until 
it becomes a fraction.

```{r}
half_it <- function(x, verbose=TRUE){
  if(verbose){
   message(sprintf("x = %s", x))
  }
  if(x < 1){
    res <- 1
  } else {
    res <- half_it(x = x/2)
  }
  return(res)
}
half_it(10)
```

This type of recursion is common when dealing with nested lists. For example, parse 
a list for however many nested levels. This is common when paginating against an API. 
Pagination refers to going through each page of results until you get to the final page.

I highly recommend a quick read by Hadley on functions that is available here: 
http://adv-r.had.co.nz/Functions.html#function-arguments

# Tidyverse Tricks

Before we get started, let's load some required packages.

```{r, message=FALSE, warning=FALSE, error=FALSE}
library(plyr)
library(dplyr)
library(tidyr)
library(purrr)
library(lubridate)
library(nycflights13)
```

## The new select() and rename() functions

In newer versions of `dplyr` you have even better version of `select()` and `rename()`. 
These functions pretty much explain themselves, but I'll include some examples.

**Code Snippet**: Convert all column names to snake case

```{r}
# only select the factor columns
as_tibble(iris) %>% select_if(is.factor)
# rename everything to make column names tidy
as_tibble(iris) %>% rename_all(~gsub('\\.', '_', tolower(.)))
```

## The everything() function for selecting columns

Also, don't forget about the handy function `everything()`. This literally selects 
every other column that you haven't already grabbed in your `select()` function. This 
is really handy when you want to re-order your columns or set things up for later reporting. 

```{r}
iris %>% 
  select(Species, everything()) %>%
  as_tibble()
```


## Using purrr's map() function

You'll hear R users talk about vectorized functions and how they are more efficient 
than running a loop. It's true that sometimes loops are necessary or they are 
easier to read. However, if you're trying to perform the same operations on everything 
in a `vector`, `list`, or row of a `data.frame`, then there are some functions to 
help you. 

In the old days, there was a package called `plyr`. It had functions that took a 
specific type of input, then repeated an operation on each element. The documentation 
for the `llply` function says it all: 
> For each element of a list, apply function, keeping results as a list.

```{r}
llply(iris, summary)
```

If you have a `data.frame` and want to perform a function for each component of it, 
then just use `dlply`: 

```{r}
dlply(iris, .(Species), summary)
```

Technically, this is not part of the tidyverse, but the inspiration for the tidyverse 
was built upon packages like **plyr**. Actually the `map()` functions in the tidyverse 
behave exactly the same: 

```{r}
map(iris, summary)
iris %>% split(.$Species) %>% map(summary)
```

Just like the **plyr** functions indicate the input and output in the function name 
**purrr* functions are the same way. The `map()` function takes a list and returns a list. 
However, `map_df()` will take a list and try to return a `data.frame`, casting the 
value as a `data.frame` and binding together if possible.

```{r}
iris %>% select_if(is.numeric) %>% map_df(summary)
```

To show a more realistic example, let's say that we need to load the iris dataset 
and add a new column with the dataset number. Here is the loop way: 

```{r}
all_dat <- NULL
for (i in 1:5){
  this_iris <- iris
  this_iris$dat_numb <- i
  all_dat <- rbind(all_dat, this_iris)
}
```

The tidyverse, **purrr** way would be: 

```{r}
map_df(1:5, ~as_tibble(mutate(iris, dat_numb=.)))
```

There are two reasons why this would be preferable: 1) It is shorter and 2) it's 10x 
slower to do it as a loop! The tradeoff is that you need to have a stronger grasp of 
how the function is operating.

## Using the modify() function

The `map()` function is inherently useful for processing lists or creating a list output. 
If you have a `data.frame` and just want to modify it in place, then you might be more 
interested in the function called `modify()`. It will take in something, transform it in place, 
and then spit it back out. 

**Code Snippet**: Convert all factors in a `data.frame` to characters. 

```{r}
as_tibble(iris) %>% modify_if(is.factor, as.character)
```

## Doing date arithmetic with lubridate

Dates are inherently weird. I highly recommend using the **lubridate** package for 
anything date related. It handles most all cases with ease. You should already be 
familiar with functions like `mdy()`, `ymd()`, `ymd_hms()`, and more. However, the 
arithmetic functions are amazingly useful and wrappers to specify units of time, like 
`months()`, `days()`, `minutes()`. They will automatically account for weird 
inconsistencies in the calendar like leap year, differing days in a month, etc. 

**Code Snippet**: Get The last day of every month in a year

```{r}
ymd('2016-01-01') + months(1:12) - days(1)
```

However, the date aware wrapper functions aren't fool proof. The functions `%m+%` 
and `%m-%`. This will add months to a date without creating a date that doesn't 
make sense.

```{r}
as.Date('2018-01-31') + months(1)
as.Date('2018-01-31') %m+% months(1)
as.Date('2018-03-30') %m-% months(1)
```

## Calculating the duration between dates and times

Another cool feature of **lubridate** is the object type `interval`. You can create one 
using `%--%` and supplying two dates or timestamps. In the example below we'll 
create an interval and show that it can quickly produce the delay time.

```{r, warning=FALSE}
our_flights <- flights %>% 
  select(year, month, day, dep_time, sched_dep_time, dep_delay) %>%
  mutate(dep_timestamp = ymd_hms(sprintf('%04d%02d%02d %04d00', year, month, day, dep_time)), 
         sched_dep_timestamp = dep_timestamp - minutes(dep_delay), 
         dep_delay_interval = sched_dep_timestamp %--% dep_timestamp) %>%
    select(dep_delay_interval, dep_delay)
our_flights
```

**Code Snippet**: Find the time in seconds between two timestamps

```{r}
our_flights %>% 
  mutate(calculated_delay = as.duration(dep_delay_interval) / dminutes(1), 
         calc_delay_secs =  as.duration(dep_delay_interval) / dseconds(1))
```

A simpler example can be done using dates.

```{r}
this_interval <- as.Date('2018-01-01') %--% as.Date('2018-02-28')
as.duration(this_interval) / dweeks(1)
as.duration(this_interval) / ddays(1)
as.duration(this_interval) / dseconds(1) # confirm it equals 58*24*60*60
```

## Calculating the ratios/sizes of groups

You are probably already familiar with using the `group_by` function to calculate a 
summary statistic for different values. However, it is often useful to `group_by` 
multiple levels if segmenting by multiple variables to gain an understanding of 
how the data is allocated within each variable. The example below calculates for 
each species of flower in the iris dataset, how many are below the average sepal length 
of the entire dataset and then the average of those flowers.

```{r}
# for reference
mean(iris$Sepal.Length)

iris %>%
  mutate(below_avg_sepal_length = as.factor(ifelse(Sepal.Length < mean(.$Sepal.Length),
                                                   "Yes", "No"))) %>%
  group_by(Species, below_avg_sepal_length) %>%
  dplyr::summarize(n = n(), 
                   avg_sepal_length = mean(Sepal.Length)) %>%
  complete(below_avg_sepal_length,
           fill = list(n = 0)) %>%
  group_by(Species) %>%
  mutate(pct_of_species_total = n / sum(n)) %>%
  ungroup() %>%
  select(Species, below_avg_sepal_length, n, pct_of_species_total, everything())
  
```

There are a few interesting components to this analysis. The first is the use of the 
function `complete()` which comes from the **tidyr** package. It will make all the 
missing combinations of a variable explicit and even comes with the option for how to 
fill in the values if missing. In this case, I specified that the count should be 
zero, which allows us to calculate the variable `pct_of_species_total`. The next 
interesting part of this flow is the second use of `group_by` which allows us to get 
the total count of observations within each species, so that we can gauge the percentage 
of below average sepal length flowers within each species. Lastly, it's always a 
good idea to invoke the function `ungroup()` because later calls to `mutate()` might 
not reflect what you expect!
